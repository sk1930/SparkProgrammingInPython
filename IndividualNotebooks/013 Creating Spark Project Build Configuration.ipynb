{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de1cf8dc-edc8-4c2e-8b38-0f93f0973366",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Welcome Back! In this section, we are going to create and run our first Spark program. And in this first lecture, we are going to create a Spark Project and define our project Build Configuration. So, Let's start. \n",
    "We will be using PyCharm as our development IDE. So I am assuming that you already have PyCharm.   You can download a free community version of PyCharm from the JetBrains website. You will also need Python, and I recommend you to get Anaconda Python installed on your machine. These two items are the prerequisite of Spark Programming using the IDE. You should also download Spark binaries and set your SPARK_HOME environment variable, as explained in the earlier lecture. However, your Spark Home should point to the correct version of Spark binaries. And what is the correct version? \n",
    "We will be using the PySpark library for Spark programming. So, you should be checking the available PySpark version. Let me visit the pypi.org and search for the pyspark. \n",
    "https://pypi.org/search/?q=pyspark\n",
    "Here it is. And this pyspark 3.5.0 one is the latest version. You can check the release history to get all available versions. So, we have these many versions. Which one do you want to use? \n",
    "Well, this decision depends upon your project and your production cluster setup. If you are developing to deploy your code on a Spark Cluster, which runs 2.4.5, then you should be selecting 2.4.5. Once you know your PySpark version, you should make sure that your Spark Binaries are also for the same version, and your Spark home is pointing to the same. Right? \n",
    "Let me show you. So, we download Apache Spark from here. \n",
    "https://spark.apache.org/downloads.html\n",
    "\n",
    "spark-3.2.4-bin-hadoop3.2 tar\n",
    "\n",
    "You can see some versions listed here. It allows you to download this tgz file. It says, spark, then version number, and Hadoop version number. \n",
    "spark-3.2.4-bin-hadoop3.2 tar\n",
    "\n",
    "I am going to use this version. And I will be using the same version of PySpark as well. Right? However, Let's assume you want to use some other version, for example, 2.4.6, but you do not see it here. Right? \n",
    "https://spark.apache.org/downloads.html\n",
    "\n",
    "You can come down and look for archives of releases. And here you have all the releases. Go to your preferred version and look for the tgz file of your interest. Here it is. It says, spark, then version number, and Hadoop version number. Right? You can see many other files, but this is the one you need. \n",
    "\n",
    "Great! Let me summarize the prerequisites to start coding Spark Applications using your IDE. \n",
    "Anaconda Platform \n",
    "PyCharm  \n",
    "Spark Binaries \n",
    "Spark Home \n",
    "Finally, if you are on the Windows platform, you need to set your Hadoop Home pointing to Hadoop win utils. Right? Don't forget to make sure that your Spark Binaries are of the same version you target for your project. Great! \n",
    "So let's start the PyCharm IDE. \n",
    "We are going to create a new project. Give a name to your project.\n",
    "C:\\Users\\Student\\Desktop\\Personal\\Spark\\HelloSpark2\n",
    "And chose your Python interpreter and the Virtual environment. We are going to use a conda environment, so make sure you selected conda in New Environment using box. Spark is not yet available on Python 3.8. So, we will use Python 3.7. The next box has already picked up the conda.exe file location.\n",
    "in my system C:\\Users\\Student\\anaconda3\\condabin\\conda.bat\n",
    "\n",
    "in his system path is anaconda3\\Scripts\\conda.exe\n",
    "So I am good at this one. Let's create the project. Wait for a few minutes while conda configures a virtual environment for you. Great! We are now ready, and the project is still empty. But before you do anything, let's install some necessary packages. Go to file->settings and look for your project name. Select the python interpreter. Make sure you are using a conda package manager. there is a conda icon symbol beside +,-, So, these are the default packages that are already included in your project. However, this is not enough. We need PySpark also. Right? Let me add the PySpark. \n",
    "\n",
    "click on + and search pyspark\n",
    "Make sure you are selecting the correct version. This version must match with your Spark Home. Here am selecting spark 3.2.4\n",
    "\n",
    "pyspark 3.2.4 is not available in anaconda package manager.\n",
    "it is available in pip but both are different and even if u do pip install pyspark ==3.2.4 ,\n",
    "conda list doesnt show the pyspark\n",
    "\n",
    "(base) C:\\Users\\Student>conda activate C:\\Users\\Student\\anaconda3\\envs\\pythonProject\n",
    "\n",
    "> conda install pyspark=3.2.4\n",
    "\n",
    "Current channels:\n",
    "\n",
    "  - https://repo.anaconda.com/pkgs/main/win-64\n",
    "  - https://repo.anaconda.com/pkgs/main/noarch\n",
    "  - https://repo.anaconda.com/pkgs/r/win-64\n",
    "  - https://repo.anaconda.com/pkgs/r/noarch\n",
    "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
    "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
    "\n",
    "To search for alternate channels that may provide the conda package you're\n",
    "looking for, navigate to\n",
    "\n",
    "    https://anaconda.org\n",
    "\n",
    "and use the search bar at the top of the page.\n",
    "\n",
    "\n",
    "\n",
    "so i am just trying to unsselect the use conda package manager in settings/ python interpreter\n",
    "\n",
    "\n",
    "Right? Done. So you got a bunch of other packages also. Those are PySpark dependencies that are pulled automatically. So we are good at PySpark. What else? Well, no program is complete without uint testing. So, you also need PyTest. Let me add it. And this time, we do not specify a version. So, the conda package manager is going to pull the latest version, which is fine. That's all we have on the packages. You might need a few others, but we will add them to other lectures as and when we need them. Now what? \n",
    "Let me create the main program. Right-click on your project, go to new, and create a Python File.\n",
    "HelloSpark\n",
    "From pyspark.sql, import everything. You need this line in every Spark program. I am assuming that you already know PythonPython. Right? So, let me create the main entry point of my PySpark program. I am going to print a Hello message and run it once. \n",
    "for me it gave a warning  UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service from . import _distributor_init\n",
    "so went to settings/python interpreter\n",
    "add interpreter \n",
    "add local interpreter \n",
    "environment -- new\n",
    "location -- C:\\Users\\Student\\Desktop\\Personal\\Spark\\pythonProject\\venv\n",
    "base interpreter : \n",
    "    C:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "\n",
    "and on runnning code again no error now\n",
    "\n",
    "\n",
    "\n",
    "It worked. Great! So we are now ready with a basic project template with all required dependencies and the main entry point. We ran it once and made sure that things are working till this stage. That's all for this video. In the next video, we are going to extend it further. See you again. Keep Learning and Keep growing."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "013 Creating Spark Project Build Configuration",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
